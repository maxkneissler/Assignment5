---
title: "Assignment V: GitHub and the ticketmaster.com API"
author: "Max Kneißler"
date: "08 2 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(rrot.dir = "C:/Users/user/Desktop/Uni Tuebingen",
      "/Masterstudium/1. Semester/Data Science Project Management/Assignment5")
```

## Introduction

The goal of this assignment is to use a public Github repository to improve the
version control system and to manage the development history of a project
carefully. We will interact with the API of ticketmaster.com in a basic and an
advanced way to obtain data from event venues in Germany and other countries in
Europe. We will make use of this data by plotting a map of Germany and 
indicating the German event locations. The procedure is repeated for Belgium and 
for Denmark as the graphical representation did not work for Germany in the 
first place.
I was working together with Nicolas Mollier (Student ID: 5640171) in this 
assignment to deepen the exchange about API and GitHub.

My public repository can be found by:
https://github.com/maxkneissler/Assignment5

To solve the assignment, the following packages are required:

```{r library, warning = FALSE, message = FALSE}
library(jsonlite)
library(httr)
library(rlist)
library(tidyverse)
library(ggplot2)
library(kableExtra)
```


## Exercise 1: Setting up a new GitHub repository

As I have not used GitHub before, I created an account and set up the repository
`Assignment5`, which can be accessed by the link presented in the introductory
part. In the following, when dealing with API requests, GitHub allows us to 
have a more efficient version control system. Through the local as well as the 
remote repository, we can access earlier versions easily if the results were not
desirable. Additionally, in case of computer problems, we know that the entire
history of the project is outsourced and can be easily accessed again by logging
into the GitHub account. Another benefit will not be used in this project, as 
I will not truly collaborate with a colleague. However, it is advisable to use
GitHub in collaborative projects to avoid miscommunications. 

I will proceed by staging smaller steps but committing just parts with a 
meaningful process such that the development history is not too cluttered and 
the steps are comprehensive. Next, we will familiarize ourselves with the API 
structure of `ticketmaster.com`.  


## Exercise 2: Getting to know the API

Getting to know the structure of the API queries on the website of 
`ticketmaster.com`, we notice that the root URL requires a package, a version, 
an api key and a resource. First, we make use of the API Explorer to obtain the 
access key, which is offered by the provider. The key is set up in a different 
R-file `api_tm` and treated secretly to maintain a high level of security. Thus, 
we get used to this structure for personal keys on other APIs.
In addition, we have a look at the `robots.txt` website of ticketmaster.com, 
which clarifies what data should not be retrieved. However, we can conclude
that the data we are interested in is not of big issue since the robots.txt-file
mostly deals with the disallowing of personal data and images.

```{r api_key, warning = FALSE, message = FALSE}
source("api_tm.R")
```

In this assignment, we will use the Discovery package as well as version v2, as 
recommended in the `Venue Search` part. In addition, we deal with a rate limit 
of 5,000 calls per day and a limit of 5 requests per second, which will be taken 
account for in the queries.


## Exercise 3: Interacting with the API - the basics

Our first request deals with event venues in Germany. Therefore, we perform a 
GET-request to extract the desired data. In order to check the success of our 
query, we have a look at the status of the request before extracting the 
content. It has to be remarked that the `locale` = `*` attribute is necessary
for a smooth request.

```{r first_GET, warning = FALSE, message = FALSE}
# Apply the query
res_venuesGermany <- GET("https://app.ticketmaster.com/discovery/v2/venues",
                       query = list(countryCode = "DE",
                                    apikey = tm_api,
                                    locale = '*'))

# Check the status
status_code(res_venuesGermany)

# Extract the content
contentTM <- fromJSON(content(res_venuesGermany, as = "text"))
```

We can see that `contentTM` includes the three subfolders `embedded`, `links`
and `page`. We can observe that more than 12,200 elements on 612 pages were 
imported. The folder `venues` contains several subfolders like images, city, 
country, name, type, id, etc. In order to follow the assignment, we are 
interested in extracting the seven characteristics `name`, `city`, `postalCode`,
`address`, `url`, `longitude` and `latitude`. In addition, some proper recoding 
is conducted such that the structure equals the output on the assignment sheet.

```{r char_extract, warning = FALSE, message = FALSE}
# Introducing the data frame
venue_data <- tibble(
  name = character(20),
  city = character(20),
  postalCode = character(20),
  address = character(20),
  url = character(20),
  longitude = character(20),
  latitude = character(20))

# Root access
content <- contentTM[["_embedded"]][["venues"]]


# Fill with the respective data
venue_data$name <- content[["name"]]

venue_data$city <- content[["city"]][["name"]]
venue_data$city <- as.character(venue_data$city)

venue_data$postalCode <- content[["postalCode"]]

venue_data$address <- content[["address"]][["line1"]]
venue_data$address <- as.character(venue_data$address)

venue_data$url <- content[["url"]]

venue_data$latitude <- content[["location"]][["latitude"]] 
venue_data$latitude <- as.double(venue_data$latitude)

venue_data$longitude <- content[["location"]][["longitude"]]
venue_data$longitude <- as.double(venue_data$longitude)


# Glimpse at the final data set
glimpse(venue_data)
```


## Exercise 4: Interacting with the API - advanced

As mentioned in the description of the GET-request, we could access about 12,236 
elements from ticketmaster.com, however, we had only a look on the first page
so far. In order to access all possible observations, we make use of a loop to
go through the different pages. First, we look at the exact amount of entries
as a flexible function since they may vary over time.

```{r count_entries, warning = FALSE, message = FALSE}
entries <- as.numeric(contentTM[["page"]][["totalElements"]])
pages <- floor(entries/500)  # number of complete pages
remainder <- entries - 500*pages
```

Then, we create another data frame with the entries, which we like to collect, 
and the corresponding size to accelerate the request. As an empty table is 
created, we start to loop through the different pages. We have to take care that
the default value of page is 0, so our loop has to start at 0 as well. We take
a size of 500 that we do not exceed for sure the request limit per day as 
Germany has many venues entries. The remaining observations on the last 
incomplete page are added manually to prevent issues with filling the table. 

```{r data_collection, warning = FALSE, message = FALSE}
# Creating the final file
venueDataComplete <- tibble(
  name = character(entries),
  city = character(entries),
  postalCode = character(entries),
  address = character(entries),
  url = character(entries),
  longitude = character(entries),
  latitude = character(entries))


# Temporary file in the loop
venueFilter <- tibble(
  name = character(500),
  city = character(500),
  postalCode = character(500),
  address = character(500),
  url = character(500),
  longitude = character(500),
  latitude = character(500))



# Loop over all pages
for (page in 0:(pages-1)) {
  
res_venuesAll <- GET("https://app.ticketmaster.com/discovery/v2/venues",
                       query = list(countryCode = "DE",
                                    page = page,
                                    size = 500,
                                    apikey = tm_api,
                                    locale = '*'))

contentAll <- fromJSON(content(res_venuesAll, as = "text"))

# Root access
content <- contentAll[["_embedded"]][["venues"]]
  

# Fill temporary file
venueFilter$name <- content[["name"]]

venueFilter$city <- content[["city"]][["name"]]

venueFilter$postalCode <- content[["postalCode"]]

venueFilter$address <- content[["address"]][["line1"]]

venueFilter$url <- content[["url"]]

venueFilter$latitude <- content[["location"]][["latitude"]]

venueFilter$longitude <- content[["location"]][["longitude"]]


# Fill in final form
venueDataComplete[(500 * (page+1) - 499):(500*(page+1)),] <- venueFilter

# Prevent exceeding the rate limit
Sys.sleep(0.25)
}


# Temporary file for remainders
venueFilter <- tibble(
  name = character(remainder),
  city = character(remainder),
  postalCode = character(remainder),
  address = character(remainder),
  url = character(remainder),
  longitude = character(remainder),
  latitude = character(remainder))



# Incomplete last page is added manually
page <- pages

res_venuesAll <- GET("https://app.ticketmaster.com/discovery/v2/venues",
                       query = list(countryCode = "DE",
                                    page = page,
                                    size = remainder,
                                    locale = '*',
                                    apikey = tm_api))
contentAll <- fromJSON(content(res_venuesAll, as = "text"))

# Root access
content <- contentAll[["_embedded"]][["venues"]]
  
# Fill temporary file
venueFilter$name <- content[["name"]]

venueFilter$city <- content[["city"]][["name"]]

venueFilter$postalCode <- content[["postalCode"]]

venueFilter$address <- content[["address"]][["line1"]]

venueFilter$url <- content[["url"]]

venueFilter$latitude <- content[["location"]][["latitude"]]

venueFilter$longitude <- content[["location"]][["longitude"]]


# Fill in final form
venueDataComplete[(500 * (pages+1) - 499):(entries),] <- venueFilter


kbl(head(venueDataComplete, 10)) %>% kable_classic(html_font = "Latex")
```


## Exercise 5: Visualizing the extracted data

We now make use of the extracted data to visualize the venues of the different 
events in Germany. In the assignment, it is already given a map-code 
of Germany, which we use.

```{r warning = FALSE, message = FALSE}
# Recoding the coordinates as numeric values
venueDataComplete$longitude <- as.double(venueDataComplete$longitude)
venueDataComplete$latitude <- as.double(venueDataComplete$latitude)

# Define the German borders 
maxLatitude <- 55.0846
minLatitude <- 47.271679
minLongitude <- 5.866944
maxLongitude <- 15.043611

# Subset of venues lying in German area
plotGER <- filter(venueDataComplete, latitude < maxLatitude, 
   latitude > minLatitude, longitude < maxLongitude, longitude > minLongitude)

# Plot of Germany
ggplot() +
  geom_polygon(
    aes(x = long, y = lat, group = group), 
                  data = map_data("world", region = "Germany"),
    fill = "grey90",color = "black") +
    geom_point(plotGER, mapping = aes(longitude, latitude), alpha = 0.4) +
    theme_void() + 
    coord_quickmap() +
    labs(title = "Event locations across Germany", 
                            caption = "Source: ticketmaster.com") +
    theme(title = element_text(size=8, face='bold'),
        plot.caption = element_text(face = "italic"))
```

We can conclude that most venues take place in the big cities Berlin, Hamburg 
and Frankfurt as well as in the Ruhr Area. In the north-west, there is a high
density of venues too. However, it can be remarked that there are venues all 
over Germany, as well in rural areas. We repeat the procedure for Belgium and
Denmark as the German extraction did not work in the first place.


## Exercise 6: Event locations in other countries

I will apply the query to Belgium and Denmark to plot the venues in the 
respective map. Just a few adjustments are necessary to obtain the desired 
result.

```{r Belgium, warning = FALSE, message = FALSE}
# Apply the query
res_venuesBELG <- GET("https://app.ticketmaster.com/discovery/v2/venues",
                       query = list(countryCode = "BE",
                                    locale = '*',
                                    apikey = tm_api))

# Extract the content
contentBE <- fromJSON(content(res_venuesBELG, as = "text"))


# Check the entries
entries <- as.numeric(contentBE[["page"]][["totalElements"]])
pages <- floor(entries/100)  # number of complete pages
remainder <- entries - 100*(pages)




# Create the final file
venueDataBE <- tibble(
  name = character(entries),
  city = character(entries),
  postalCode = character(entries),
  address = character(entries),
  url = character(entries),
  longitude = character(entries),
  latitude = character(entries))


# Temporary file for the loop
venueFilter <- tibble(
  name = character(100),
  city = character(100),
  postalCode = character(100),
  address = character(100),
  url = character(100),
  longitude = character(100),
  latitude = character(100))


# Loop over all pages
for (page in 0:(pages-1)) {
  
res_venuesAll <- GET("https://app.ticketmaster.com/discovery/v2/venues",
                       query = list(countryCode = "BE",
                                    size = 100,
                                    page = page,
                                    locale = '*',
                                   apikey = tm_api))

contentAll <- fromJSON(content(res_venuesAll, as = "text"))


# Root access
content <- contentAll[["_embedded"]][["venues"]]
  

venueFilter$name <- content[["name"]]

venueFilter$city <- content[["city"]][["name"]]

venueFilter$postalCode <- content[["postalCode"]]

venueFilter$address <- content[["address"]][["line1"]]

venueFilter$url <- content[["url"]]

venueFilter$latitude <- content[["location"]][["latitude"]]
venueFilter$longitude <- content[["location"]][["longitude"]]

venueDataBE[(100 * (page+1) - 99):(100*(page+1)),] <- venueFilter

# Prevent exceeding the rate limit
Sys.sleep(0.25)
}


# Temporary file for remainders
venueFilter <- tibble(
  name = character(remainder),
  city = character(remainder),
  postalCode = character(remainder),
  address = character(remainder),
  url = character(remainder),
  longitude = character(remainder),
  latitude = character(remainder))


# Incomplete last page is added manually
page <- pages

res_venuesAll <- GET("https://app.ticketmaster.com/discovery/v2/venues",
                       query = list(countryCode = "BE",
                                    page = page,
                                    size = remainder,
                                    locale = '*',
                                    apikey = tm_api))

contentAll <- fromJSON(content(res_venuesAll, as = "text"))


# Root access
content <- contentAll[["_embedded"]][["venues"]]


venueFilter$name <- content[["name"]]

venueFilter$city <- content[["city"]][["name"]]

venueFilter$postalCode <- content[["postalCode"]]

venueFilter$address <- content[["address"]][["line1"]]

venueFilter$url <- content[["url"]]

venueFilter$latitude <- content[["location"]][["latitude"]]
venueFilter$longitude <- content[["location"]][["longitude"]]


# Fill in final form
venueDataBE[(100 * (pages+1) - 99):(entries),] <- venueFilter


kbl(head(venueDataBE, 10)) %>% kable_classic(html_font = "Latex")
```

Now, we make use of the map to plot the corresponding venues into the map of 
Belgium. In order to visualize only the venues which are actually located in 
Belgium we filter the data to drop outliers instead of assigning missing values. 

```{r Belgium_plot, warning = FALSE, message = FALSE}
# Recode the coordiantes
venueDataBE$longitude <- as.double(venueDataBE$longitude)
venueDataBE$latitude <- as.double(venueDataBE$latitude)

# Filter for only locations in Belgium
maxLatitude <- 51.456975083419564
minLatitude <- 49.820905125023124
minLongitude <- 2.580427185176589
maxLongitude <- 6.403329194705428

plotBE <- filter(venueDataBE, latitude < maxLatitude, latitude > minLatitude, 
                          longitude < maxLongitude, longitude > minLongitude)

# Plot the border with venues
ggplot() +
  geom_polygon(aes(x = long, y = lat, group = group), 
                  data = map_data("world", region = "Belgium"),
                    fill = "grey90",color = "black") +
  geom_point(data = plotBE, 
                  aes(longitude, latitude), alpha = 0.3, col = "#b4a069") +
  theme_void() + 
  coord_quickmap() +
  labs(title = "Event locations across Belgium", 
                            caption = "Source: ticketmaster.com") +
  theme(title = element_text(size=8, face='bold'),
        plot.caption = element_text(face = "italic"))
```

We can clearly see that most venues take place in the big cities Brussels,
Antwerp, Ghent and Liège. A few other events are also located near the ocean.

We will apply the same procedure to venues in Denmark.

```{r Denmark, warning = FALSE, message = FALSE}
# Apply the query
res_venuesDK <- GET("https://app.ticketmaster.com/discovery/v2/venues",
                       query = list(countryCode = "DK",
                                    locale = '*',
                                    apikey = tm_api))

# Extract the content
contentDK <- fromJSON(content(res_venuesDK, as = "text"))


# Check the entries
entries <- as.numeric(contentDK[["page"]][["totalElements"]])
pages <- floor(entries/100)  # number of complete pages
remainder <- entries - 100*(pages)




# Create the final file
venueDataDK <- tibble(
  name = character(entries),
  city = character(entries),
  postalCode = character(entries),
  address = character(entries),
  url = character(entries),
  longitude = character(entries),
  latitude = character(entries))


# Temporary file for the loop
venueFilter <- tibble(
  name = character(100),
  city = character(100),
  postalCode = character(100),
  address = character(100),
  url = character(100),
  longitude = character(100),
  latitude = character(100))


# Loop over all pages
for (page in 0:(pages-1)) {
  
res_venuesAll <- GET("https://app.ticketmaster.com/discovery/v2/venues",
                       query = list(countryCode = "DK",
                                    size = 100,
                                    page = page,
                                    locale = '*',
                                    apikey = tm_api))

contentAll <- fromJSON(content(res_venuesAll, as = "text"))

# Root access
content <- contentAll[["_embedded"]][["venues"]]
  

venueFilter$name <- content[["name"]]

venueFilter$city <- content[["city"]][["name"]]

venueFilter$postalCode <- content[["postalCode"]]

venueFilter$address <- content[["address"]][["line1"]]

venueFilter$url <- content[["url"]]

venueFilter$latitude <- content[["location"]][["latitude"]]
venueFilter$longitude <- content[["location"]][["longitude"]]

venueDataDK[(100 * (page+1) - 99):(100*(page+1)),] <- venueFilter

# Prevent exceeding the rate limit
Sys.sleep(0.25)
}


# Temporary file for remainders
venueFilter <- tibble(
  name = character(remainder),
  city = character(remainder),
  postalCode = character(remainder),
  address = character(remainder),
  url = character(remainder),
  longitude = character(remainder),
  latitude = character(remainder))


# Incomplete last page is added manually
page <- pages

res_venuesAll <- GET("https://app.ticketmaster.com/discovery/v2/venues",
                       query = list(countryCode = "DK",
                                    page = page,
                                    size = remainder,
                                    locale = '*',
                                   apikey = tm_api))
contentAll <- fromJSON(content(res_venuesAll, as = "text"))


# Root access
content <- contentAll[["_embedded"]][["venues"]]

  
venueFilter$name <- content[["name"]]

venueFilter$city <- content[["city"]][["name"]]

venueFilter$postalCode <- content[["postalCode"]]

venueFilter$address <- content[["address"]][["line1"]]

venueFilter$url <- content[["url"]]

venueFilter$latitude <- content[["location"]][["latitude"]]
venueFilter$longitude <- content[["location"]][["longitude"]]


# Fill in final form
venueDataDK[(100 * (pages+1) - 99):(entries),] <- venueFilter


kbl(head(venueDataDK, 10)) %>% kable_classic(html_font = "Latex")
```

As the data is extracted, we make once again use of the map to plot the borders
with the venues.

```{r Denmark_plot, warning = FALSE, message = FALSE}
# Recode the coordinates
venueDataDK$longitude <- as.double(venueDataDK$longitude)
venueDataDK$latitude <- as.double(venueDataDK$latitude)

# Filter for venues only located in Denmark
maxLatitude <- 57.74530877878669
minLatitude <- 54.590310107590064
minLongitude <- 7.984077284485842
maxLongitude <- 13.120607292800624

plotDK <- filter(venueDataDK, latitude < maxLatitude, latitude > minLatitude, 
                          longitude < maxLongitude, longitude > minLongitude)

# Plot the borders with the venues
ggplot() +
  geom_polygon(
    aes(x = long, y = lat, group = group), 
                  data = map_data("world", region = "Denmark"),
    fill = "grey90",color = "black") +
    geom_point(data = plotDK, 
               aes(longitude, latitude), alpha = 0.3, col = "red") +
    theme_void() + 
    coord_quickmap() +
    labs(title = "Event locations across Denmark", 
                            caption = "Source: ticketmaster.com") +
    theme(title = element_text(size=8, face='bold'),
        plot.caption = element_text(face = "italic"))
```

As for Belgium, we see that most events take place either in Copenhagen or in
Aarhus, which are the biggest cities in Denmark. However, there are venues all
over the country.



---
title: "Assignment5"
author: "Max Knei√üler"
date: "28 1 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(rrot.dir = "C:/Users/user/Desktop/Uni Tuebingen",
      "/Masterstudium/1. Semester/Data Science Project Management/Assignment5")
```

## Introduction

The goal of this assignment to use a public Github repository to improve the
version control system and to manage the development history of this project
carefully. We will interact with the API of ticketmaster.com in a basic and an
advanced way to obtain data from event venues in Germany. We will make use of
this data by plotting a map of Germany, indicating the event locations in
Germany. In addition, this procedure is repeated for another European country.
I was working together with Elias Rudolph (Student ID: 5629871) and Nicolas 
Mollier (Student ID: 5640171)in this assignment to deepen the exchange about 
API and GitHub.

My public repository can be found by:
https://github.com/maxkneissler/Assignment5

To solve the assignment, the following packages are needed:

```{r library, warning = FALSE, message = FALSE}
library(jsonlite)
library(httr)
library(rlist)
library(tidyverse)
library(naniar)
library(ggplot2)
```


## Exercise 1: Setting up a new GitHub repository

As I have not used GitHub before, I created an account and set up a repository
`Assignment5`, which can be accessed by the link presented in the introductory
part. In the following, when dealing with API requests, GitHub allows us to 
have a more efficient version control system. Through the local as well as the 
remote repository, we can access earlier versions easily if the results were not
desirable. Additionally, in case of computer problems, we know that the entire
history of the project is outsourced and can be easily accessed again by logging
into the Github account. Another benefit will not be used in this project, as 
I will not truly collaborate with a colleague. However, it is advisable to use
GitHub in collaborative projects to avoid miscommunications. 

I will proceed by staging smaller steps but committing just parts with a 
meaningful process such that the development history is not too crowded and 
the steps are comprehensive. Next, we will familiarize ourselves with the API 
structure of ticketmaster.com.  


## Exercise 2: Getting to know the API

Getting to know the structure of the API queries on the website of 
ticketmaster.com, we see that the URI-format requires a package, a version, an
api key and a resource. First, we make use of the API Explorer to obtain the 
access key, which is offered by the provider. The key is set up in a different 
R-file `api_tm` and treated secretly to maintain a high certain level of 
security and to get used to this file structure for personal keys on other APIs.
In addition, we have a look at the `robots.txt` website of ticketmaster.com, 
which clarifies what data should not be retrieved. However, we can conclude
that the data we are interested is not of big issue since the robots.txt-file
mostly deals with the disallowing of personal data and images.

```{r api_key, warning = FALSE, message = FALSE}
source("api_tm.R")
```


In this assignment, we will use the Discovery package as well as version v2, as 
recommended in the `Venue Search` part. In addition, we deal with a rate limit 
of 5,000 calls per day and a limit of 5 requests per second, which will be taken 
account for in the queries. 


## Exercise 3: Interacting with the API - the basics

Our first request deals with the content of event venues in Germany. Therefore,
we perform a GET-request to extract the desired data. In order to check the 
success of our query, we check the status before extracting the content.

```{r first_GET, warning = FALSE, message = FALSE}
# Query in proper format
query <- 
  paste0(
    "https://app.ticketmaster.com/discovery/v2/venues.json?countryCode=DE&apikey=",
    tm_api)

# Apply the query
res_venuesGermany <- GET(query)


# Check the status
status_code(res_venuesGermany)

# Extract the content
contentTM <- fromJSON(content(res_venuesGermany, as = "text"))
```

We can see that `contentTM` includes the three subfolders `embedded`, `links`
and `page`. We can observe that 4738 elements on 238 pages were imported. 
The folder `venues` on the other hand contains several subfolders like images,
city, country, name, type, id, etc. In order to follow the assignment, we are 
interested in extracting the seven characteristics `name`, `city`, `postalCode`,
`address`, `url`, `longitude` and `latitude`. In addition, some proper recoding
is conducted.

```{r char_extract, warning = FALSE, message = FALSE}
# Content as data frame
venue_data <- tibble(contentTM[["_embedded"]][["venues"]])


# extract only the desired entries
venue_data <- venue_data[,c(1, 10, 8, 12, 5)] 

# longitude and latitude as "location"
venue_data$latitude <- 
  contentTM[["_embedded"]][["venues"]][["location"]][["latitude"]] 
venue_data$latitude <- as.double(venue_data$latitude)

venue_data$longitude <- 
  contentTM[["_embedded"]][["venues"]][["location"]][["longitude"]]
venue_data$longitude <- as.double(venue_data$longitude)

# some recoding of the variables
venue_data$city <- as.character(venue_data$city)
venue_data$address <- as.character(venue_data$address)

# many missing values with locations -> just first two rows exist
glimpse(venue_data)
```


## Exercise 4: Interacting with the API - advanced




## Exercise 5: Visualizing the extracted data



## Exercise 6: Event locations in other countries



